# chatPDF - Sistema Inteligente de Chat con PDFs

![Python](https://img.shields.io/badge/Python-3.12-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28-red)
![License](https://img.shields.io/badge/License-MIT-yellow)

Sistema avanzado de chat conversacional para documentos PDF basado en **GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG)** y **arquitectura multi-modelo**.

<!-- ![Demo](docs/demo.gif) -->
<!-- *[Opcional: agregar gif de demo mÃ¡s adelante]* -->

---

## ğŸš€ CaracterÃ­sticas Principales

- âœ… **Multi-Modelo Inteligente**: Groq (Llama 3.1) + Ollama (Llama 3.2) con fallback automÃ¡tico
- âœ… **BÃºsqueda HÃ­brida**: SemÃ¡ntica (embeddings) + Keywords para datos especÃ­ficos
- âœ… **OCR AutomÃ¡tico**: Procesa PDFs escaneados con Tesseract
- âœ… **Anti-AlucinaciÃ³n**: Sistema de validaciÃ³n en 3 capas (92% precisiÃ³n)
- âœ… **Citas de Fuentes**: Cada respuesta cita pÃ¡gina y fragmento del PDF
- âœ… **Multi-Documento**: GestiÃ³n de mÃºltiples PDFs simultÃ¡neos
- âœ… **Modo Offline**: Funciona sin internet usando Ollama

---

## ğŸ“Š Resultados

| MÃ©trica | Valor | vs ChatPDF | Mejora |
|---------|-------|------------|--------|
| **PrecisiÃ³n** | 92% | 73% | +26% |
| **Alucinaciones** | 4% | 18% | -78% |
| **Latencia** | 2.8s | 4.2s | -33% |
| **Uptime** | 99.1% | 87% | +14% |

---

## ğŸ—ï¸ Arquitectura

```
Usuario â†’ Streamlit â†’ FastAPI â†’ Multi-Model Manager
                                     â”œâ”€ Groq (Llama 3.1)
                                     â””â”€ Ollama (Llama 3.2)
                         â†“
                   ChromaDB (Vectores) + Hybrid Search
```

---

## âš™ï¸ InstalaciÃ³n RÃ¡pida

### Requisitos Previos

1. **Python 3.11+**: https://www.python.org/downloads/
2. **Tesseract OCR**: https://github.com/UB-Mannheim/tesseract/wiki
3. **Poppler**: https://github.com/oschwartz10612/poppler-windows/releases/
4. **Ollama**: https://ollama.com/download

### ConfiguraciÃ³n

```bash
# 1. Clonar repositorio
git clone https://github.com/TU_USUARIO/deepPDF-backend.git
cd deepPDF-backend

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
.\venv\Scripts\Activate.ps1  # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Descargar modelo Ollama
ollama pull llama3.2:1b

# 5. Configurar API Key de Groq
export GROQ_API_KEY="gsk_tu_key_aqui"  # Linux/Mac
# o
$env:GROQ_API_KEY="gsk_tu_key_aqui"  # Windows
```

**Obtener Groq API Key (GRATIS)**: https://console.groq.com/

---

## ğŸ¯ Uso

```bash
# Terminal 1 - Backend
python main.py

# Terminal 2 - Frontend
streamlit run frontend.py
```

Abrir navegador en: **http://localhost:8501**

### Ejemplo de Uso

1. Subir PDF(s) en el sidebar
2. Click en "ğŸš€ Procesar PDFs"
3. Hacer preguntas:
   - "Â¿De quÃ© trata el documento?"
   - "Â¿CuÃ¡l es el nÃºmero de expediente?"
   - "Resume el contenido en 3 puntos"

---

## ğŸ“ Estructura del Proyecto

```
deepPDF-backend/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ pdf_reader.py           # ExtracciÃ³n + OCR
â”‚   â”œâ”€â”€ embeddings_manager.py   # Chunking + VectorizaciÃ³n
â”‚   â”œâ”€â”€ multi_model_manager.py  # Sistema multi-modelo
â”‚   â”œâ”€â”€ hybrid_search.py        # BÃºsqueda hÃ­brida
â”‚   â”œâ”€â”€ ask_manager.py          # Orquestador
â”‚   â””â”€â”€ memory_manager.py       # Historial chat
â”œâ”€â”€ frontend.py                 # UI Streamlit
â”œâ”€â”€ main.py                     # API FastAPI
â”œâ”€â”€ requirements.txt            # Dependencias
â””â”€â”€ README.md                   # Este archivo
```

---

## ğŸ§ª Testing

```bash
# Prueba con documento de ejemplo
python -m pytest tests/

# Benchmark de precisiÃ³n
python benchmark.py --dataset evaluation/
```

---

## ğŸ› ï¸ TecnologÃ­as

- **Backend**: FastAPI, Uvicorn
- **Frontend**: Streamlit
- **LLMs**: Groq API (Llama 3.1), Ollama (Llama 3.2)
- **Embeddings**: Sentence-Transformers (`all-MiniLM-L6-v2`)
- **Vector DB**: ChromaDB
- **OCR**: Tesseract + Poppler

---

## ğŸ“š DocumentaciÃ³n

- [Manual de InstalaciÃ³n Completo](docs/INSTALACION.md)
- [Arquitectura Detallada](docs/ARQUITECTURA.md)
- [Paper AcadÃ©mico](docs/paper.pdf)
- [API Documentation](http://localhost:8000/docs) (cuando el backend estÃ© corriendo)

---

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas:

1. Fork el proyecto
2. Crear una rama (`git checkout -b feature/mejora`)
3. Commit cambios (`git commit -m 'Agrega nueva funciÃ³n'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abrir Pull Request

---

## ğŸ—ºï¸ Roadmap

- [ ] Integrar GPT-4 Vision para interpretar grÃ¡ficos
- [ ] Clustering jerÃ¡rquico para >100 documentos
- [ ] Fine-tuning en dominio legal/mÃ©dico
- [ ] API pÃºblica con rate limiting
- [ ] Deploy en la nube (AWS/Azure)
- [ ] App mÃ³vil

---

## ğŸ“„ Licencia

MIT License - ver [LICENSE](LICENSE) para mÃ¡s detalles

---

## ğŸ‘¥ Autores

**Jose Alfredo Huaman Quispe**  
**Augusto Fernando Mamani Palomino**

Escuela Profesional de IngenierÃ­a InformÃ¡tica y de Sistemas  
Universidad Nacional de San Antonio Abad del Cusco

---

## ğŸ™ Agradecimientos

- [LangChain](https://github.com/langchain-ai/langchain) por el framework RAG
- [Groq](https://groq.com/) por la API ultra-rÃ¡pida
- [Ollama](https://ollama.ai/) por modelos locales
- Comunidad de [Sentence-Transformers](https://www.sbert.net/)

---

## ğŸ“§ Contacto

Para dudas o colaboraciones:
- Email: 225422@unsaac.edu.pe, 224870@unsaac.edu.pe

---

**Desarrollado en Cusco, PerÃº ğŸ‡µğŸ‡ª**
